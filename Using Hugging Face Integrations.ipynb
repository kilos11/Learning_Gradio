{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"V28","mount_file_id":"1q2OV4ssAVY2K9Ziupczl6YrBE1fVqMx5","authorship_tag":"ABX9TyPuIPe8V6MFUuw9cnv+k5y0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"code","source":["!pip install virtualenv"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"ppIL0RjuHffD","executionInfo":{"status":"ok","timestamp":1718643243362,"user_tz":-120,"elapsed":10754,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"}},"outputId":"7c5ce52b-779d-40a4-9b17-c8a9ea1fa5c0"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting virtualenv\n","  Downloading virtualenv-20.26.2-py3-none-any.whl (3.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting distlib<1,>=0.3.7 (from virtualenv)\n","  Downloading distlib-0.3.8-py2.py3-none-any.whl (468 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.9/468.9 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock<4,>=3.12.2 in /usr/local/lib/python3.10/dist-packages (from virtualenv) (3.14.0)\n","Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from virtualenv) (4.2.2)\n","Installing collected packages: distlib, virtualenv\n","Successfully installed distlib-0.3.8 virtualenv-20.26.2\n"]}]},{"cell_type":"code","source":["!virtualenv myenv"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"106RvpCZH6pj","executionInfo":{"status":"ok","timestamp":1718643314454,"user_tz":-120,"elapsed":5210,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"}},"outputId":"ff290bd5-4561-4126-e683-46e4ebc20b0b"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["created virtual environment CPython3.10.12.final.0-64 in 387ms\n","  creator CPython3Posix(dest=/content/myenv, clear=False, no_vcs_ignore=False, global=False)\n","  seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/root/.local/share/virtualenv)\n","    added seed packages: pip==24.0, setuptools==69.5.1, wheel==0.43.0\n","  activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator\n"]}]},{"cell_type":"code","source":["!source myenv/bin/activate"],"metadata":{"id":"DHNHNsyMIGsf","executionInfo":{"status":"ok","timestamp":1718643359466,"user_tz":-120,"elapsed":449,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["!pip install --upgrade huggingface_hub"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"VMvFh1sqJAZz","executionInfo":{"status":"ok","timestamp":1718643606175,"user_tz":-120,"elapsed":4472,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"}},"outputId":"bf145d14-1e7f-4457-8899-ab7e848c6734"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.23.3)\n","Collecting huggingface_hub\n","  Downloading huggingface_hub-0.23.4-py3-none-any.whl (402 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m402.6/402.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.14.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.6.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.4)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.6.2)\n","Installing collected packages: huggingface_hub\n","  Attempting uninstall: huggingface_hub\n","    Found existing installation: huggingface-hub 0.23.3\n","    Uninstalling huggingface-hub-0.23.3:\n","      Successfully uninstalled huggingface-hub-0.23.3\n","Successfully installed huggingface_hub-0.23.4\n"]}]},{"cell_type":"code","source":["!python -c \"from huggingface_hub import model_info; print(model_info('gpt2'))\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UclWoqh4JX2h","executionInfo":{"status":"ok","timestamp":1718643710776,"user_tz":-120,"elapsed":1156,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"}},"outputId":"9c47cd5a-857c-4cc8-ee44-4ccceb3be1b1"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["ModelInfo(id='openai-community/gpt2', author='openai-community', sha='607a30d783dfa663caf39e06633721c8d4cfcd7e', created_at=datetime.datetime(2022, 3, 2, 23, 29, 4, tzinfo=datetime.timezone.utc), last_modified=datetime.datetime(2024, 2, 19, 10, 57, 45, tzinfo=datetime.timezone.utc), private=False, gated=False, disabled=False, downloads=7477549, likes=2019, library_name='transformers', tags=['transformers', 'pytorch', 'tf', 'jax', 'tflite', 'rust', 'onnx', 'safetensors', 'gpt2', 'text-generation', 'exbert', 'en', 'doi:10.57967/hf/0039', 'license:mit', 'autotrain_compatible', 'endpoints_compatible', 'text-generation-inference', 'region:us'], pipeline_tag='text-generation', mask_token=None, card_data={'base_model': None, 'datasets': None, 'eval_results': None, 'language': 'en', 'library_name': None, 'license': 'mit', 'license_name': None, 'license_link': None, 'metrics': None, 'model_name': None, 'pipeline_tag': None, 'tags': ['exbert']}, widget_data=[{'text': 'My name is Julien and I like to'}, {'text': 'My name is Thomas and my main'}, {'text': 'My name is Mariama, my favorite'}, {'text': 'My name is Clara and I am'}, {'text': 'My name is Lewis and I like to'}, {'text': 'My name is Merve and my favorite'}, {'text': 'My name is Teven and I am'}, {'text': 'Once upon a time,'}], model_index=None, config={'architectures': ['GPT2LMHeadModel'], 'model_type': 'gpt2', 'tokenizer_config': {}}, transformers_info=TransformersInfo(auto_model='AutoModelForCausalLM', custom_class=None, pipeline_tag='text-generation', processor='AutoTokenizer'), siblings=[RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None), RepoSibling(rfilename='64-8bits.tflite', size=None, blob_id=None, lfs=None), RepoSibling(rfilename='64-fp16.tflite', size=None, blob_id=None, lfs=None), RepoSibling(rfilename='64.tflite', size=None, blob_id=None, lfs=None), RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None), RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None), RepoSibling(rfilename='flax_model.msgpack', size=None, blob_id=None, lfs=None), RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None), RepoSibling(rfilename='merges.txt', size=None, blob_id=None, lfs=None), RepoSibling(rfilename='model.safetensors', size=None, blob_id=None, lfs=None), RepoSibling(rfilename='onnx/config.json', size=None, blob_id=None, lfs=None), RepoSibling(rfilename='onnx/decoder_model.onnx', size=None, blob_id=None, lfs=None), RepoSibling(rfilename='onnx/decoder_model_merged.onnx', size=None, blob_id=None, lfs=None), RepoSibling(rfilename='onnx/decoder_with_past_model.onnx', size=None, blob_id=None, lfs=None), RepoSibling(rfilename='onnx/generation_config.json', size=None, blob_id=None, lfs=None), RepoSibling(rfilename='onnx/merges.txt', size=None, blob_id=None, lfs=None), RepoSibling(rfilename='onnx/special_tokens_map.json', size=None, blob_id=None, lfs=None), RepoSibling(rfilename='onnx/tokenizer.json', size=None, blob_id=None, lfs=None), RepoSibling(rfilename='onnx/tokenizer_config.json', size=None, blob_id=None, lfs=None), RepoSibling(rfilename='onnx/vocab.json', size=None, blob_id=None, lfs=None), RepoSibling(rfilename='pytorch_model.bin', size=None, blob_id=None, lfs=None), RepoSibling(rfilename='rust_model.ot', size=None, blob_id=None, lfs=None), RepoSibling(rfilename='tf_model.h5', size=None, blob_id=None, lfs=None), RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None), RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None), RepoSibling(rfilename='vocab.json', size=None, blob_id=None, lfs=None)], spaces=['open-llm-leaderboard/open_llm_leaderboard', 'microsoft/HuggingGPT', 'Gustavosta/MagicPrompt-Stable-Diffusion', 'shi-labs/Versatile-Diffusion', 'optimum/llm-perf-leaderboard', 'h2oai/h2ogpt-chatbot', 'microsoft/Promptist', 'yizhangliu/Grounded-Segment-Anything', 'aliabid94/AutoGPT', 'wangrongsheng/ChatPaper', 'h2oai/h2ogpt-chatbot2', 'OFA-Sys/OFA-Image_Caption', 'Manmay/tortoise-tts', 'Intel/low_bit_open_llm_leaderboard', 'ShiwenNi/ChatReviewer', 'OpenMotionLab/MotionGPT', 'm-ric/beam_search_visualizer', 'eduagarcia/open_pt_llm_leaderboard', 'exbert-project/exbert', 'flax-community/image-captioning', 'doevent/Stable-Diffusion-prompt-generator', 'treadon/prompt-fungineer-355M', 'SeaLLMs/SeaLLM-7B', 'nateraw/lavila', 'yizhangliu/Text-to-Image', 'BAAI/open_cn_llm_leaderboard', 'gsaivinay/open_llm_leaderboard', 'deepklarity/poster2plot', 'EleutherAI/magma', 'akhaliq/CLIP_prefix_captioning', 'FrankZxShen/so-vits-svc-models-ba', 'maxmax20160403/sovits5.0', 'OFA-Sys/OFA-Visual_Grounding', 'OFA-Sys/OFA-vqa', 'Gustavosta/MagicPrompt-Dalle', 'phenomenon1981/MagicPrompt-Stable-Diffusion', 'OFA-Sys/OFA-Generic_Interface', 'johko/capdec-image-captioning', 'TMElyralab/MuseTalk', 'hkunlp/Binder', 'aubmindlab/Arabic-NLP', 'bipin/image2story', 'ShiwenNi/ChatResponse', 'LilyF/Generate_Text_and_Audio', 'society-ethics/model-card-regulatory-check', 'Omnibus/Chatbot-Compare', 'Catmeow/AI_story_writing', 'hahahafofo/image2text_prompt_generator', 'ICML2022/OFA', 'thirdai/BOLT2.5B', 'mshukor/UnIVAL', 'sohaibcs1/Image-to-Text-Summary', 'aliabid94/GPT-Golf', 'Hello-SimpleAI/chatgpt-detector-ling', 'SeaLLMs/SeaLLM-7B-v2.5', 'llizhx/TinyGPT-V', 'FrankZxShen/so-vits-svc-models-pcr', 'RitaParadaRamos/SmallCapDemo', 'architext/Architext_deployed', 'kmacdermid/RpgRoomGenerator', 'SeViLA/SeViLA', 'AnimaLab/bias-test-gpt-pairs', 'sasha/BiasDetection', 'stanfordnlp/Backpack-Demo', 'gsarti/pecore', 'GTBench/GTBench', 'sasha/WinoBiasCheck', 'ccolas/TastyPiano', 'BoomerangGirl/MagicPrompt-Stable-Diffusion', 'dromerosm/gpt-info-extraction', 'hahahafofo/prompt_generator', 'liyucheng/selective_context', 'zeno-ml/chatbot-report', 'Hellisotherpeople/HF-SHAP', 'ethzanalytics/gpt2-xl-conversational', 'taesiri/HuggingGPT-Lite', 'lfoppiano/document-qa', 'shangdatalab-ucsd/LDB', 'Guinnessgshep/AI_story_writing', 'taka-yamakoshi/tokenizer-demo', 'autonomous019/image_story_generator', 'luis112/text-generation-webui', 'SeaLLMs/SeaLLM-7B-v2', 'gagan3012/ViTGPT2', 'abdullahmeda/detect-ai-text', 'ehristoforu/Rensor', 'BigSalmon/InformalToFormal', 'alistairmcleay/cambridge-masters-project', 'codeparrot/apps_metric', 'Catmeow/Text_Generation_Fine_Tune', 'j43fer/MagicPrompt-Stable-Diffusion', 'Daniton/MagicPrompt-Stable-Diffusion', 'ashhadahsan/ai-book-generator', 'Chakshu123/sketch-colorization-with-hint', 'koajoel/PolyFormer', 'felixz/open_llm_leaderboard', 'yhavinga/dutch-tokenizer-arena', 'xzuyn/Token-Count-Comparison', 'zjunlp/EasyEdit', 'neuroama/so-vits-svc'], safetensors=SafeTensorsInfo(parameters={'F32': 137022720}, total=137022720))\n"]}]},{"cell_type":"markdown","source":["#**Hosting your Gradio demos on Spaces**#\n","##Hugging Face Spaces allows anyone to host their Gradio demos freely, and uploading your Gradio demos take a couple of minutes. You can head to `hf.co/new-space`, select the Gradio SDK, create an app.py file, and voila! You have a demo you can share with anyone else. To learn more, read this guide how to host on Hugging Face Spaces using the website.\n","\n","##Alternatively, you can create a Space programmatically, making use of the huggingface_hub client library library. Here's an example:"],"metadata":{"id":"1-VguS_XNNgf"}},{"cell_type":"code","source":["from huggingface_hub import (\n","    create_repo,\n","    get_full_repo_name,\n","    upload_file,\n",")\n","\n","create_repo(name=target_space_name,\n","            token=hf_token,\n","            repo_type=\"space\",\n","            space_sdk=\"gradio\")\n","\n","repo_name = get_full_repo_name(\n","    model_id=target_space_name,\n","    token=hf_token\n",")\n","\n","file_url = upload_file(\n","    path_or_fileobj=\"file.txt\",\n","    path_in_repo=\"app.py\",\n","    repo_id=repo_name,\n","    repo_type=\"space\",\n","    token=hf_token,\n",")"],"metadata":{"id":"M5opmo5nL-Fm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#**Loading demos from Spaces**#\n","##You can also use and remix existing Gradio demos on Hugging Face Spaces. For example, you could take two existing Gradio demos on Spaces and put them as separate tabs and create a new demo. You can run this new demo locally, or upload it to Spaces, allowing endless possibilities to remix and create new demos!\n","\n","##Here's an example that does exactly that:"],"metadata":{"id":"8Ehb1lTyOV1S"}},{"cell_type":"code","source":["import gradio as gr\n","\n","with gr.Blocks() as demo:\n","    with gr.Tab(\"Translate to Spanish\"):\n","        gr.load(\"gradio/en2es\", src=\"spaces\")\n","    with gr.Tab(\"Translate to French\"):\n","        gr.load(\"abidlabs/en2fr\", src=\"spaces\")\n","\n","demo.launch()"],"metadata":{"id":"y-cm25clOe8o"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#**Demos with the Pipeline in transformers**#\n","##Hugging Face's popular transformers library has a very easy-to-use abstraction, `pipeline()` that handles most of the complex code to offer a simple API for common tasks. By specifying the task and an (optional) model, you can build a demo around an existing model with few lines of Python:"],"metadata":{"id":"a0qhD3j5PDxi"}},{"cell_type":"code","source":["import gradio as gr\n","from transformers import pipeline\n","\n","pipe = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-es\")\n","\n","def predict(text):\n","    return pipe(text)[0][\"translation_text\"]\n","\n","demo = gr.Interface(\n","    fn=predict,\n","    inputs='text',\n","    outputs='text',\n",")\n","\n","demo.launch()\n"],"metadata":{"id":"8FSZ1nIIPVjn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##But gradio actually makes it even easier to convert a pipeline to a demo, simply by using the `gradio.Interface.from_pipeline` methods, which skips the need to specify the input and output components:"],"metadata":{"id":"1o1JRWsEQkMl"}},{"cell_type":"code","source":["from transformers import pipeline\n","import gradio as gr\n","\n","pipe = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-es\")\n","\n","demo = gr.Interface.from_pipeline(pipe)\n","demo.launch()"],"metadata":{"id":"lBMP4VFvQyyf"},"execution_count":null,"outputs":[]}]}