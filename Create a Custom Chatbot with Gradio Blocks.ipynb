{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOHlkeBAozBOfF9ptTpdICw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"dhLby9zO_yrM","executionInfo":{"status":"ok","timestamp":1718725197485,"user_tz":-120,"elapsed":32712,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"}},"outputId":"94b6fa80-4ff1-4cef-a4f1-6149d8f79eae"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting gradio\n","  Downloading gradio-4.36.1-py3-none-any.whl (12.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiofiles<24.0,>=22.0 (from gradio)\n","  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n","Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n","Collecting fastapi (from gradio)\n","  Downloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting ffmpy (from gradio)\n","  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting gradio-client==1.0.1 (from gradio)\n","  Downloading gradio_client-1.0.1-py3-none-any.whl (318 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.1/318.1 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting httpx>=0.24.1 (from gradio)\n","  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.23.3)\n","Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.0)\n","Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n","Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n","Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n","Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.25.2)\n","Collecting orjson~=3.0 (from gradio)\n","  Downloading orjson-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n","Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.3)\n","Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n","Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.7.3)\n","Collecting pydub (from gradio)\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Collecting python-multipart>=0.0.9 (from gradio)\n","  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n","Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n","Collecting ruff>=0.2.2 (from gradio)\n","  Downloading ruff-0.4.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting semantic-version~=2.0 (from gradio)\n","  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n","Collecting tomlkit==0.12.0 (from gradio)\n","  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n","Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.3)\n","Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n","Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.7)\n","Collecting uvicorn>=0.14.0 (from gradio)\n","  Downloading uvicorn-0.30.1-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.0.1->gradio) (2023.6.0)\n","Collecting websockets<12.0,>=10.0 (from gradio-client==1.0.1->gradio)\n","  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.6.2)\n","Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n","  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.3.1)\n","Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio)\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.14.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.4)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.53.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.18.4)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n","Collecting starlette<0.38.0,>=0.37.2 (from fastapi->gradio)\n","  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting fastapi-cli>=0.0.2 (from fastapi->gradio)\n","  Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n","Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi->gradio)\n","  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting email_validator>=2.0.0 (from fastapi->gradio)\n","  Downloading email_validator-2.1.2-py3-none-any.whl (30 kB)\n","Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi->gradio)\n","  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.35.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.16.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.24.1->gradio) (1.2.1)\n","Collecting httptools>=0.5.0 (from uvicorn>=0.14.0->gradio)\n","  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn>=0.14.0->gradio)\n","  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n","Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn>=0.14.0->gradio)\n","  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn>=0.14.0->gradio)\n","  Downloading watchfiles-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n","Building wheels for collected packages: ffmpy\n","  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=caee2e299b44f767b030b7f5dbdde328e0e90dacbb0fdc5981666a85a74d40b7\n","  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n","Successfully built ffmpy\n","Installing collected packages: pydub, ffmpy, websockets, uvloop, ujson, tomlkit, semantic-version, ruff, python-multipart, python-dotenv, orjson, httptools, h11, dnspython, aiofiles, watchfiles, uvicorn, starlette, httpcore, email_validator, httpx, gradio-client, fastapi-cli, fastapi, gradio\n","Successfully installed aiofiles-23.2.1 dnspython-2.6.1 email_validator-2.1.2 fastapi-0.111.0 fastapi-cli-0.0.4 ffmpy-0.3.2 gradio-4.36.1 gradio-client-1.0.1 h11-0.14.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 orjson-3.10.5 pydub-0.25.1 python-dotenv-1.0.1 python-multipart-0.0.9 ruff-0.4.9 semantic-version-2.10.0 starlette-0.37.2 tomlkit-0.12.0 ujson-5.10.0 uvicorn-0.30.1 uvloop-0.19.0 watchfiles-0.22.0 websockets-11.0.3\n"]}],"source":["!pip install --upgrade gradio"]},{"cell_type":"markdown","source":["# Comments:\n","# This code creates a simple chatbot interface using the Gradio library.\n","# The `gradio`, `random`, and `time` libraries are imported.\n","# The Gradio interface is created using the `gr.Blocks()` context manager.\n","# A `gr.Chatbot()` component is initialized to display the chat history.\n","# A `gr.Textbox()` component is created for the user to input messages.\n","# A `gr.ClearButton()` component is created to clear the Textbox and Chatbot.\n","# The `respond` function is defined to generate bot responses.\n","# Inside the `respond` function, a random bot message is chosen from a list.\n","# The user message and bot response are appended to the `chat_history` list.\n","# A delay of 2 seconds is simulated using `time.sleep(2)` to mimic a bot's response time.\n","# The Textbox is cleared, and the updated `chat_history` is returned.\n","# The `msg.submit()` method connects the Textbox and Chatbot components to the `respond` function.\n","# When the user submits a message, the `respond` function is called with the message and chat history.\n","# The `respond` function generates a random bot response, updates the chat history, and returns the updated state.\n","# Finally, the Gradio interface is launched using `demo.launch()`.\n","# This simple chatbot interface will respond with random messages from the predefined list.\n","# The chat history is displayed in the Chatbot component, and the user can clear the interface using the Clear button."],"metadata":{"id":"cNBXW-04DG1i"}},{"cell_type":"code","source":["import gradio as gr  # Import the Gradio library for building web-based interfaces\n","import random  # Import the random library to select random bot responses\n","import time  # Import the time library to add delays\n","\n","# Create a Gradio Blocks interface\n","with gr.Blocks() as demo:\n","    # Create a Chatbot component\n","    chatbot = gr.Chatbot()\n","    # Create a Textbox component for user input\n","    msg = gr.Textbox()\n","    # Create a ClearButton to clear the message and chatbot history\n","    clear = gr.ClearButton([msg, chatbot])\n","\n","    # Define a function to generate a bot response\n","    def respond(message, chat_history):\n","        # Choose a random response from the predefined list\n","        bot_message = random.choice([\"How are you?\",\n","                                     \"I love you\",\n","                                     \"I'm very hungry\"])\n","        # Append the user message and bot response to the chat history\n","        chat_history.append((message, bot_message))\n","        # Simulate a delay to mimic thinking time\n","        time.sleep(2)\n","        # Return an empty string to clear the input box and the updated chat history\n","        return \"\", chat_history\n","\n","    # Set up the submit action on the textbox to call the respond function\n","    msg.submit(respond, [msg, chatbot], [msg, chatbot])\n","\n","# Launch the Gradio interface\n","demo.launch()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":646},"collapsed":true,"id":"MkqiGkQoBMKu","executionInfo":{"status":"ok","timestamp":1718725963465,"user_tz":-120,"elapsed":5794,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"}},"outputId":"c63d2932-0211-4227-c999-cc9d808aa2c0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n","\n","Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","Running on public URL: https://fc446e1fa5ff156100.gradio.live\n","\n","This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://fc446e1fa5ff156100.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","source":["#**Add Streaming to your Chatbot**#\n","##There are several ways we can improve the user experience of the chatbot above. First, we can stream responses so the user doesn't have to wait as long for a message to be generated. Second, we can have the user message appear immediately in the chat history, while the chatbot's response is being generated. Here's the code to achieve that:"],"metadata":{"id":"GrMsCnM-EKeP"}},{"cell_type":"markdown","source":["# Comments:\n","# This code creates a chatbot interface using the Gradio library.\n","# The `gradio`, `random`, and `time` libraries are imported.\n","# The Gradio interface is created using the `gr.Blocks()` context manager.\n","# A `gr.Chatbot()` component is initialized to display the chat history.\n","# A `gr.Textbox()` component is created for the user to input messages.\n","# A `gr.Button()` component is created to clear the chat history.\n","# The `user` function is defined to handle user input.\n","# Inside the `user` function, the user message is appended to the `history` list.\n","# The `bot` function is defined to generate bot responses.\n","# Inside the `bot` function, a random bot message is chosen from a list.\n","# The previous bot response is cleared from the `history` list.\n","# The bot message is simulated to be typed character by character with a delay of 0.05 seconds.\n","# The updated `history` list is yielded after each character is added.\n","# The `msg.submit()` method connects the Textbox and Chatbot components to the `user` and `bot` functions.\n","# When the user submits a message, the `user` function is called, and its output is passed to the `bot` function.\n","# The `bot` function generates a response, simulating typing, and updates the chat history.\n","# The `clear.click()` method connects the Clear button to reset the Chatbot component.\n","# The `demo.queue()` method starts the Gradio queue, allowing the interface to update asynchronously.\n","# Finally, the Gradio interface is launched using `demo.launch()`.\n","# This chatbot interface will respond with random messages from the predefined list.\n","# The bot response is simulated to be typed character by character, creating a typing effect.\n","# The chat history is displayed in the Chatbot component, and the user can clear the interface using the Clear button."],"metadata":{"id":"Z4XuqUFmPyLt"}},{"cell_type":"code","source":["import gradio as gr\n","import random\n","import time\n","\n","# Create a Gradio interface\n","with gr.Blocks() as demo:\n","    # Initialize a Chatbot component\n","    chatbot = gr.Chatbot()\n","\n","    # Create a Textbox component for user input\n","    msg = gr.Textbox()\n","\n","    # Create a Clear button\n","    clear = gr.Button(\"Clear\")\n","\n","    # Define a function to handle user input\n","    def user(user_message, history):\n","        # Append the user message to the chat history\n","        return \"\", history + [[user_message, None]]\n","\n","    # Define a function to generate bot responses\n","    def bot(history):\n","        # Generate a random bot message\n","        bot_message = random.choice([\n","            \"How are you?\",\n","            \"I love you\",\n","            \"I'm very hungry\"\n","        ])\n","\n","        # Clear the previous bot response\n","        history[-1][1] = \"\"\n","\n","        # Simulate typing the bot response character by character\n","        for character in bot_message:\n","            history[-1][1] += character\n","            time.sleep(0.05)  # Delay between each character\n","            yield history  # Yield the updated chat history\n","\n","    # Connect the Textbox and Chatbot components to the user and bot functions\n","    msg.submit(\n","        user,\n","        [msg, chatbot],\n","        [msg, chatbot],\n","        queue=False).then(\n","            bot,\n","            chatbot,\n","            chatbot\n","        )\n","    # Connect the Clear button to reset the Chatbot\n","    clear.click(lambda: None, None, chatbot, queue=False)\n","\n","# Start the Gradio queue\n","demo.queue()\n","\n","# Launch the Gradio interface\n","demo.launch()\n","\n"],"metadata":{"id":"RVjeRKEWEtJy","colab":{"base_uri":"https://localhost:8080/","height":646},"collapsed":true,"executionInfo":{"status":"ok","timestamp":1718729357896,"user_tz":-120,"elapsed":1631,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"}},"outputId":"30b53788-10cf-406b-8d85-b07914d6b7aa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n","\n","Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","Running on public URL: https://1e212b7334458e979b.gradio.live\n","\n","This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://1e212b7334458e979b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["#**Liking / Disliking Chat Messages**#\n","##Once you've created your `gr.Chatbot`, you can add the ability for users to `like` or `dislike` messages. This can be useful if you would like users to vote on a bot's responses or flag inappropriate results.\n","\n","##To add this functionality to your Chatbot, simply attach a `.like()` event to your Chatbot. A chatbot that has the `.like()` event will automatically feature a thumbs-up icon and a thumbs-down icon next to every bot message.\n","\n","##The `.like()` method requires you to pass in a function that is called when a user clicks on these icons. In your function, you should have an argument whose type is `gr.LikeData`. Gradio will automatically supply the parameter to this argument with an object that contains information about the liked or disliked message. Here's a simplistic example of how you can have users like or dislike chat messages:"],"metadata":{"id":"ouxOX3ZWRGc9"}},{"cell_type":"markdown","source":["# Comments:\n","# This code creates a simple chatbot interface using the Gradio library.\n","# The `gradio` library is imported.\n","# The `greet` function is defined to handle user input and generate a greeting.\n","# Inside the `greet` function, the user input and a greeting are appended to the `history` list.\n","# The `vote` function is defined to handle upvotes and downvotes.\n","# Inside the `vote` function, a message is printed indicating whether the user upvoted or downvoted a response.\n","# The Gradio interface is created using the `gr.Blocks()` context manager.\n","# A `gr.Chatbot()` component is initialized to display the chat history.\n","# A `gr.Textbox()` component is created for the user to input messages.\n","# The `textbox.submit()` method connects the Textbox and Chatbot components to the `greet` function.\n","# When the user submits a message, the `greet` function is called with the message and chat history.\n","# The `greet` function generates a greeting and updates the chat history.\n","# The `chatbot.like()` method adds like/dislike icons to the Chatbot and connects them to the `vote` function.\n","# When the user upvotes or downvotes a response, the `vote` function is called with the like/dislike data.\n","# The `vote` function prints a message indicating whether the response was upvoted or downvoted.\n","# Finally, the Gradio interface is launched using `demo.launch()`.\n","# This chatbot interface will greet the user with a \"Hello, [user input]\" message.\n","# The chat history is displayed in the Chatbot component, and the user can upvote or downvote responses using the like/dislike icons."],"metadata":{"id":"tKiZ9T8vTlzf"}},{"cell_type":"code","source":["import gradio as gr\n","\n","# Define a function to handle user input and generate a greeting\n","def greet(history, input):\n","    # Append the user input and a greeting to the chat history\n","    return history + [(input, \"Hello, \" + input)]\n","\n","# Define a function to handle upvotes and downvotes\n","def vote(data: gr.LikeData):\n","    # Check if the user upvoted or downvoted\n","    if data.liked:\n","        print(\"You upvoted this response: \" + data.value)\n","    else:\n","        print(\"You downvoted this response: \" + data.value)\n","\n","# Create a Gradio interface\n","with gr.Blocks() as demo:\n","    # Initialize a Chatbot component\n","    chatbot = gr.Chatbot()\n","\n","    # Create a Textbox component for user input\n","    textbox = gr.Textbox()\n","\n","    # Connect the Textbox and Chatbot components to the greet function\n","    textbox.submit(greet, [chatbot, textbox], [chatbot])\n","\n","    # Add like/dislike icons to the Chatbot and connect them to the vote function\n","    chatbot.like(vote, None, None)\n","\n","# Launch the Gradio interface\n","demo.launch()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":646},"id":"nhAes7gTSGXK","executionInfo":{"status":"ok","timestamp":1718730343636,"user_tz":-120,"elapsed":1357,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"}},"outputId":"e0d45695-09f2-4030-b671-9304944847f1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n","\n","Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","Running on public URL: https://8e04a2fe92ad93bf42.gradio.live\n","\n","This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://8e04a2fe92ad93bf42.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["#**Adding Markdown, Images, Audio, or Videos**#\n","##The `gr.Chatbot` component supports a subset of markdown including `bold`, `italics`, and code. For example, we could write a function that responds to a user's message, with a bold `That's cool!`, like this:"],"metadata":{"id":"vQyeutk4Vpgy"}},{"cell_type":"code","source":["def bot(history):\n","    response = \"**That's cool!**\"\n","    history[-1][1] = response\n","    return history"],"metadata":{"id":"K5101aQQV_Ma"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##In addition, it can handle media files, such as images, audio, and video. You can use the MultimodalTextbox component to easily upload all types of media files to your chatbot. To pass in a media file, we must pass in the file as a tuple of two strings, like this: `(filepath, alt_text)`. The `alt_text` is optional, so you can also just pass in a tuple with a single element `(filepath,)`, like this:"],"metadata":{"id":"3lmgYhF8Wx4T"}},{"cell_type":"markdown","source":["# Comments:\n","# This function is designed to handle adding messages to a chat history in a Gradio application.\n","# It takes two arguments: `history` (the current chat history) and `message` (the new message to be added).\n","# The function first iterates through the files in the `message` dictionary.\n","# For each file, it appends the file path to the `history` list as a tuple with `None` as the second element.\n","# If the `message` dictionary contains text (i.e., `message[\"text\"]` is not `None`), it appends the text to the `history` list as a tuple with `None` as the second element.\n","# Finally, the function returns the updated `history` list and a new `gr.MultimodalTextbox` component from the Gradio library.\n","# The `gr.MultimodalTextbox` component is configured to be non-interactive (`interactive=False`) and to accept image files (`file_types=[\"image\"]`).\n","# This function can be used in a Gradio application to handle user messages that may contain text and/or files.\n","# The updated chat history and the `gr.MultimodalTextbox` component can be used to display the chat history and allow the user to send new messages with text and/or files."],"metadata":{"id":"XEMd7l7gZZqt"}},{"cell_type":"code","source":["def add_message(history, message):\n","    # Iterate over the list of files in the message\n","    for x in message[\"files\"]:\n","        # Append each file's path to the history as a tuple (file path, None)\n","        history.append(((x[\"path\"],), None))\n","\n","    # Check if the message contains text\n","    if message[\"text\"] is not None:\n","        # Append the text to the history as a tuple (text, None)\n","        history.append((message[\"text\"], None))\n","\n","    # Return the updated history and a new instance of gr.MultimodalTextbox\n","    # The textbox is reset with no value, non-interactive, and only accepts image files\n","    return history, gr.MultimodalTextbox(value=None, interactive=False, file_types=[\"image\"])"],"metadata":{"id":"Rc-BfLoGYCot"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Putting this together, we can create a multimodal chatbot with a multimodal textbox for a user to submit text and media files. The rest of the code looks pretty much the same as before:"],"metadata":{"id":"IGx3a6_DZxV1"}},{"cell_type":"markdown","source":["##Explanation:\n","##Imports:\n","\n","##gradio as gr: Gradio library for creating interactive web interfaces.\n","##os: Operating system library (though not used in this script).\n","##time: Library to add delays (used for simulating typing).\n","##Functions:\n","\n","##print_like_dislike: Prints details of like/dislike interactions, including index, value, and status.\n","##add_message: Adds the user's message (text or file) to the chat history and resets the input box.\n","##bot: Simulates a bot response with a streaming text effect, where each character is added with a delay.\n","##Interface Setup:\n","\n","##Chatbot Component: Initialized with specific settings.\n","##MultimodalTextbox: For user input, allowing images and text.\n","##Submit Action: When the user submits a message, add_message is called to update the history.\n","##Bot Response: After adding the message, the bot's response is generated with a streaming effect using the bot function.\n","##Like/Dislike: Adds like/dislike icons to the chatbot and associates interactions with the print_like_dislike function.\n","##Launching the Interface:\n","\n","##demo.queue(): Enables handling multiple interactions in sequence.\n","##demo.launch(): Launches the Gradio interface, making it accessible for user interactions.\n","##This setup creates an interactive chatbot that supports multimodal input, streams text responses, and allows users to like or dislike messages."],"metadata":{"id":"gNE4y0yijDBE"}},{"cell_type":"markdown","source":["# Comments:\n","# This code creates a chatbot interface using the Gradio library.\n","# The `gradio`, `os`, and `time` libraries are imported.\n","# The `print_like_dislike` function is defined to handle like/dislike events.\n","# The `add_message` function is defined to handle adding messages to the chat history.\n","# The `bot` function is defined to simulate a bot response.\n","# The Gradio interface is created using the `gr.Blocks()` context manager.\n","# A `gr.Chatbot()` component is initialized to display the chat history.\n","# A `gr.MultimodalTextbox()` component is created for the user to input messages and upload files.\n","# The `chat_input.submit()` method connects the MultimodalTextbox to the `add_message` function.\n","# The `chat_msg.then()` method connects the `add_message` output to the `bot` function.\n","# The `bot_msg.then()` method resets the `chat_input` component after the bot response.\n","# The `chatbot.like()` method adds like/dislike icons to the Chatbot and connects them to the `print_like_dislike` function.\n","# The `demo.queue()` method starts the Gradio queue, allowing the interface to update asynchronously.\n","# Finally, the Gradio interface is launched using `demo.launch()`.\n","# This chatbot interface allows the user to input text and upload files.\n","# The bot responds with a simple message, simulating typing character by character.\n","# The chat history is displayed in the Chatbot component, and the user can like/dislike responses using the like/dislike icons.\n","# The code demonstrates the use of Gradio components, event handling, and asynchronous updates."],"metadata":{"id":"D3XaRLX3izig"}},{"cell_type":"code","source":["import gradio as gr  # Import the Gradio library for building web-based interfaces\n","import os  # Import the os library for interacting with the operating system (though not used in this script)\n","import time  # Import the time library to add delays\n","\n","# Function to print details of a like or dislike interaction\n","def print_like_dislike(x: gr.LikeData):\n","    # Print the index, value, and like status of the interaction\n","    print(x.index, x.value, x.liked)\n","\n","# Function to add a message to the chat history\n","def add_message(history, message):\n","    # Iterate over the list of files in the message\n","    for x in message[\"files\"]:\n","        # Append each file's details to the history as a tuple ((file details,), None)\n","        history.append(((x,), None))\n","\n","    # Check if the message contains text\n","    if message[\"text\"] is not None:\n","        # Append the text to the history as a tuple (text, None)\n","        history.append((message[\"text\"], None))\n","\n","    # Return the updated history and a reset multimodal textbox\n","    return history, gr.MultimodalTextbox(value=None, interactive=False)\n","\n","# Function to simulate the bot's response with streaming text\n","def bot(history):\n","    # Define the bot's response\n","    response = \"**That's cool!**\"\n","    # Initialize the response part of the last entry in history\n","    history[-1][1] = \"\"\n","    for character in response:\n","        # Add each character to the response\n","        history[-1][1] += character\n","        # Simulate typing delay\n","        time.sleep(0.05)\n","        # Yield the updated history for streaming effect\n","        yield history\n","\n","# Create a Gradio Blocks interface\n","with gr.Blocks() as demo:\n","    # Create a Chatbot component with specific settings\n","    chatbot = gr.Chatbot(\n","        [],\n","        elem_id=\"chatbot\",\n","        bubble_full_width=False\n","    )\n","\n","    # Create a MultimodalTextbox for user input, allowing images and text\n","    chat_input = gr.MultimodalTextbox(\n","        interactive=True,\n","        file_types=[\"image\"],\n","        placeholder=\"Enter message or upload file...\",\n","        show_label=False\n","\n","    )\n","\n","    # Set up the submit action on the textbox to call the add_message function\n","    chat_msg = chat_input.submit(\n","        add_message,\n","        [chatbot, chat_input],\n","        [chatbot, chat_input]\n","    )\n","\n","    # Set up a follow-up action to call the bot function after the message is added\n","    bot_msg = chat_msg.then(\n","        bot,\n","        chatbot,\n","        chatbot,\n","        api_name=\"bot_response\"\n","    )\n","\n","    # Reset the input box to interactive mode after the bot response\n","    bot_msg.then(\n","        lambda: gr.MultimodalTextbox(interactive=True),\n","        None,\n","        [chat_input]\n","    )\n","\n","    # Add like/dislike icons to the chatbot and set up the print_like_dislike function to handle interactions\n","    chatbot.like(print_like_dislike, None, None)\n","\n","# Enable the queue for handling multiple interactions and launch the Gradio interface\n","demo.queue()\n","demo.launch()\n","\n"],"metadata":{"id":"3Jutzh31ayRi","colab":{"base_uri":"https://localhost:8080/","height":646},"executionInfo":{"status":"ok","timestamp":1718734409276,"user_tz":-120,"elapsed":1833,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"}},"outputId":"f5ca690f-cc88-44c6-dab2-cca7d4c94e24"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n","\n","Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","Running on public URL: https://ef3c78222702c51996.gradio.live\n","\n","This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://ef3c78222702c51996.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":5}]}]}